# [Publications in NeuIPS 2024](https://nips.cc/Conferences/2024/Schedule)

## Accept domain statistics
 - **[Time Series Forecasting: ](#time-series-forecasting)**
 - **[Time Series Representation Learning: ](#time-series-representation-learning)**
 - **[Time Series Generative Learning: ](#time-series-generative-earning)**
 - **[Time Series Analysis: ](#time-series-analysis)**
 - **[Miscellaneous: ](#miscellaneous)**
  

### Con4m: Context-aware Consistency Learning Framework for Segmented Time Series Classification
- [[paper](https://arxiv.org/pdf/2408.00041)]
- [**Team**] Yang Yang, Zhejiang University
- 时间序列分类（TSC）包括两种设置：对整个序列进行分类或对分段子序列进行分类。分段TSC的原始时间序列通常包含多个类，每个类的持续时间（MVD）各不相同。因此，MVD的特点对分段TSC提出了独特的挑战，但在很大程度上被现有的研究所忽视。具体而言，在MVD内要分类的连续实例（段）之间存在自然的时间依赖性。然而，主流TSC模型依赖于独立同分布（i.i.d.）的假设，侧重于对每个细分市场进行独立建模。此外，具有不同专业知识的注释器可能会提供不一致的边界标签，导致无噪声TSC模型的性能不稳定。为了应对这些挑战，我们首先正式证明，有价值的上下文信息可以增强分类实例的判别能力。利用MVD在数据和标签层面的上下文先验，我们提出了一种新的一致性学习框架Con4m，该框架有效地利用了更有利于区分分段TSC任务中连续片段的上下文信息，同时协调了不一致的边界标签进行训练。跨多个数据集的广泛实验验证了Con4m在处理MVD上的分段TSC任务方面的有效性

### Segment, Shuffle, and Stitch: A Simple Mechanism for Improving Time-Series Representations
- [[paper](https://arxiv.org/pdf/2405.20082)]
- 有的学习时间序列表示的方法保持了时间步长的时间排列不变，并假设原始顺序是学习的最佳顺序。然而，现实世界时间序列的非相邻部分可能具有很强的依赖性。因此，我们提出了一个问题：是否有一种时间序列的替代安排，可以实现更有效的表征学习？为了解决这个问题，我们提出了一种简单的即插即用机制，称为Segment、Shuffle和Stitch（S3），旨在改进现有模型的时间序列表示学习。S3的工作原理是从原始序列中创建不重叠的片段，并以最适合手头任务的学习方式对其进行洗牌。然后，它将混洗的片段重新连接在一起，并对原始输入执行学习加权求和，以捕获新混洗的序列和原始序列。S3是模块化的，可以堆叠以创建不同程度的粒度，并且可以添加到多种形式的神经架构中，包括CNN或Transformer，计算开销可以忽略不计。通过在几个数据集和最先进的基线上进行广泛的实验，我们表明，结合S3可以显著改善时间序列分类和预测任务，使某些数据集的性能提高68%。我们还表明，与原始基线相比，S3使学习更加稳定，训练损失曲线和损失景观更平滑

### Exploiting Representation Curvature for Boundary Detection in Time Series
- 边界是时间序列中某个类发生变化的时间戳。最近，基于表示的边界检测越来越受欢迎，但它对连续距离差的强调适得其反，尤其是在变化是渐进的情况下。在本文中，我们提出了一种基于新的变化度量（表示轨迹的曲率）的边界检测方法RECURVE，以适应渐变和突变。这里，表示空间中的一系列表示被解释为轨迹，并且可以计算每个时间戳处的曲率。利用随机游走理论，我们正式证明了边界附近的平均曲率低于其他点。使用不同真实世界时间序列数据集的广泛实验证实了RECURVE优于最先进的方法。

### Medformer: A Multi-Granularity Patching Transformer for Medical Time-Series Classification
- [[paper](https://arxiv.org/pdf/2405.20082)]
- 医学时间序列（MedTS）数据，如脑电图（EEG）和心电图（ECG），在医疗保健中起着至关重要的作用，如诊断脑部和心脏病。现有的MedTS分类方法主要依赖于手工制作的生物标志物提取和基于CNN的模型，对基于变压器的模型的探索有限。在本文中，我们介绍了Medformer，一种专门为MedTS分类量身定制的多粒度配线变压器。我们的方法结合了三种新机制来利用MedTS的独特特性：跨通道修补以利用通道间相关性，多粒度嵌入以捕获不同尺度的特征，以及两阶段（粒度内和粒度间）多粒度自我关注以学习粒度内和粒度间的特征和相关性。我们在受试者依赖和具有挑战性的受试者独立设置下对五个公共数据集进行了广泛的实验。结果表明，Medformer在10个基线上具有优势，在所有六个评估指标的五个数据集上都取得了最高的平均排名。这些发现强调了我们的方法对医疗保健应用的重大影响，例如诊断心肌梗死、阿尔茨海默氏症和帕金森氏症。

### Large Pre-trained time series models for cross-domain Time series analysis tasks
- [[paper](https://arxiv.org/pdf/2311.11413)]
- 大型预训练模型在语言和视觉等领域的最新进展中至关重要，使单个下游任务的模型训练更加高效，并提供卓越的性能。然而，处理时间序列分析任务通常需要从头开始设计和训练一个单独的模型，利用特定于该任务的训练数据和领域专业知识。我们解决了从多域时间序列数据集中预训练基础时间序列模型的一个重大挑战：从不同域的异构时间序列中提取语义上有用的标记化输入到模型中。我们提出了大型预训练时间序列模型（LPTM），该模型引入了一种新的自适应分割方法，可以在预训练期间自动识别最佳的数据集特定分割策略。这使得LPTM在对不同的下游时间序列分析任务进行微调时，在零样本设置下，能够执行类似于或优于领域特定的最新模型。与最先进的基线相比，LPTM实现了卓越的预测和时间序列分类结果，数据量减少了40%，训练时间减少了50%。
