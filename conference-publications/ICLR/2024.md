# [Publications in ICLR 2024](https://openreview.net/group?id=ICLR.cc/2024/Conference#tab-accept-oral)

## Time Series Forecasting
### Multi-scale Transformers with Adaptive Pathways for Time Series Forecasting
 - [paper](https://openreview.net/attachment?id=lJkOCMP2aW&name=pdf)
 - 基于 Transformer 的模型在时间序列预测方面取得了一些成功。 现有方法主要从有限或固定的尺度对时间序列进行建模，这使得捕获跨不同尺度的不同特征具有挑战性。 在本文中，我们提出了具有自适应路径的多尺度变压器（Pathformer）。 所提出的 Transformer 集成了时间分辨率和时间距离以进行多尺度建模。 多尺度划分使用不同大小的块将时间序列划分为不同的时间分辨率。 基于每个尺度的划分，对这些补丁执行双重关注，以捕获全局相关性和局部细节作为时间依赖性。 我们进一步丰富了具有自适应路径的多尺度变压器，它根据输入时间序列中变化的时间动态自适应地调整多尺度建模过程，提高了 Pathformer 的预测精度和泛化能力。 对九个真实世界数据集的大量实验表明，Pathformer 不仅超越了当前所有模型，实现了最先进的性能，而且在各种传输场景下表现出了更强的泛化能力。
   
### VQ-TR: Vector Quantized Attention for Time Series Forecasting
 - [paper](https://openreview.net/attachment?id=IxpTsFS7mh&name=pdf)
 - 概率时间序列预测是一个具有挑战性的问题，因为涉及的序列较长，准确的概率推理需要大量样本，并且许多应用程序需要实时推理。 这些挑战需要不仅准确而且计算高效的方法。 不幸的是，当前最先进的时间序列预测方法都是基于 Transformer，由于序列长度的二次复杂性，其扩展性很差，因此计算效率低下。 此外，除了少数例外，这些方法仅针对非概率点估计进行了评估。 在这项工作中，我们解决了这两个缺点。 首先，我们引入 VQ-TR，它将大序列映射到一组离散的潜在表示，作为注意力模块的一部分。 这不仅使我们能够关注序列长度具有线性复杂性的较大上下文窗口，而且还允许有效的正则化以避免过度拟合。 对于第二个问题，我们提供了据我们所知对现代基于 Transformer 的概率预测时间序列预测方法的首次系统比较。 在此比较中，我们发现 VQ-TR 的性能比所有其他方法更好或相当，同时计算效率较高。
   
### Multi-Resolution Diffusion Models for Time Series Forecasting
 - [paper](https://openreview.net/attachment?id=mmjnr0G8ZY&name=pdf)
 - 扩散模型已成功用于许多计算机视觉应用，例如文本引导的图像生成和图像到图像的翻译。 最近，有人尝试扩展时间序列数据的扩散模型。 然而，这些扩展相当简单，并且没有利用时间序列数据的独特属性。 由于不同的模式通常在时间序列的多个尺度上表现出来，因此我们在本文中利用这种多分辨率时间结构并提出了多分辨率扩散模型（mr-Diff）。 通过使用季节趋势分解，我们从时间序列中依次提取从细到粗的趋势以进行前向扩散。 然后，去噪过程以一种由易到难的非自回归方式进行。 首先生成最粗略的趋势。 使用预测的粗略趋势作为条件变量，逐步添加更精细的细节。 九个真实世界时间序列数据集的实验结果表明，mr-Diff 优于最先进的时间序列扩散模型。 它也优于或可比各种高级时间序列预测模型。

### CARD: Channel Aligned Robust Blend Transformer for Time Series Forecasting
 - [paper](https://openreview.net/attachment?id=MJksrOhurE&name=pdf)
 - [code](https://anonymous.4open.science/r/CARD-6EEC)
 - 最近的研究证明了 Transformer 模型在时间序列预测方面的强大功能。 Transformer 成功的关键要素之一是提高训练鲁棒性的通道无关（CI）策略。 然而，忽略 CI 中不同通道之间的相关性会限制模型的预测能力。 在这项工作中，我们设计了一种特殊的 Transformer，即通道对齐鲁棒混合变压器（Channel Aligned Robust Blend Transformer，简称 CARD），它解决了 CI 型 Transformer 在时间序列预测中的关键缺点。 首先，CARD 引入了通道对齐的注意力结构，使其能够捕获信号之间的时间相关性以及多个变量之间随时间的动态依赖性。 其次，为了有效利用多尺度知识，我们设计了一个令牌混合模块来生成具有不同分辨率的令牌。 第三，我们引入了用于时间序列预测的稳健损失函数，以减轻潜在的过度拟合问题。 这种新的损失函数根据预测不确定性对有限范围内的预测重要性进行加权。 我们对多个长期和短期预测数据集的评估表明，CARD 显着优于最先进的时间序列预测方法。
   
### Transformer-Modulated Diffusion Models for Probabilistic Multivariate Time Series Forecasting
 - [paper](https://openreview.net/attachment?id=qae04YACHs&name=pdf)
 - Transformer 在多元时间序列 (MTS) 预测中得到了广泛应用，提供了令人印象深刻的性能。 尽管如此，这些现有的基于变压器的方法往往忽略了一个重要方面：将不确定性纳入预测序列，这在决策中具有重要价值。 在本文中，我们引入了变压器调制扩散模型（TMDM），将条件扩散生成过程与变压器结合到一个统一的框架中，以实现 MTS 的精确分布预测。 TMDM 利用变压器的力量从历史时间序列数据中提取重要的见解。 然后，该信息被用作先验知识，捕获扩散模型内正向和反向过程中的协变量依赖性。 此外，我们将精心设计的基于变压器的预测方法无缝集成到 TMDM 中，以提高其整体性能。 此外，我们引入了两个新的指标来评估不确定性估计性能。 通过使用四个评估指标对六个数据集进行广泛的实验，我们确定了 TMDM 在概率 MTS 预测中的有效性。

### Interpretable Sparse System Identification: Beyond Recent Deep Learning Techniques on Time-Series Prediction
 - [paper](https://openreview.net/attachment?id=aFWUY3E7ws&name=pdf)
 - 随着神经网络方法的不断进步，时间序列预测在过去几十年中引起了人们的极大兴趣。 然而，神经网络的可解释性不足，并且利用深度学习技术进行预测需要大量的计算支出，导致其在许多场景中的应用变得困难。 为了应对这一挑战，本研究提出了一种可解释的稀疏系统识别方法，该方法不需要通过反向传播进行耗时的训练。 该方法融合了基于知识和数据驱动方法的优点，利用傅里叶基础并考虑数据背后的长期趋势和短期波动来构建字典函数。 利用l1范数进行稀疏优化，可以获得具有显式稀疏表达函数和极高准确度的预测结果。 该方法的性能评估是在综合基准数据集上进行的，包括 ETT、Exchange 和 ILI。 结果表明，根据最新最先进的深度学习方法，我们提出的方法总体显着提高了 20% 以上。 此外，我们的方法展示了仅在 CPU 上的高效训练能力。 因此，这项研究可能会对时间序列重建和预测领域有所启发。

### Copula Conformal prediction for multi-step time series prediction
 - [paper](https://openreview.net/attachment?id=ojIJZDNIBj&name=pdf)
 - 准确的不确定性测量是构建稳健可靠的机器学习系统的关键步骤。 共形预测是一种无分布的不确定性量化算法，因其易于实现、统计覆盖范围保证以及底层预测器的多功能性而广受欢迎。 然而，现有的时间序列共形预测算法仅限于单步预测，没有考虑时间依赖性。 在本文中，我们提出了用于多元、多步时间序列预测的 Copula 保形预测算法，CopulaCPTS。 我们证明了CopulaCPTS具有有限样本有效性保证。 在四个合成和现实世界的多元时间序列数据集上，我们表明 CopulaCPTS 比现有技术为多步骤预测任务生成更校准和更有效的置信区间。
   
### Towards Transparent Time Series Forecasting
 - [paper](https://openreview.net/attachment?id=TYXtXLYHpR&name=pdf)
 - 透明的机器学习 (ML) 模型对于确保决策系统的可解释性和可信性至关重要，特别是在医疗保健、金融和刑事司法等高风险领域。 虽然透明的机器学习模型已被提出用于分类和回归，但时间序列预测为确保透明度带来了一些独特的挑战。 特别是，当前使用的自下而上的方法侧重于特定时间点（通常间隔时间）的时间序列值，并不能提供对整个时间序列的整体理解。 这限制了机器学习在许多关键领域的适用性。 为了为机器学习打开这些领域，我们提出了一个自上而下的双层透明度框架，其中涉及了解预测时间序列的较高级别趋势和较低级别属性。 应用该框架，我们开发了 TIMEVIEW，这是一种基于静态特征的透明机器学习模型，用于时间序列预测，并辅以交互式可视化工具。 通过一系列实验，我们展示了我们方法的有效性和可解释性，为机器学习在各个领域更透明和可靠的应用铺平了道路。
   
### iTransformer: Inverted Transformers Are Effective for Time Series Forecasting 
 - [paper](https://openreview.net/attachment?id=JePfAI8fah&name=pdf)
 - 最近线性预测模型的繁荣对基于 Transformer 的预测器的架构修改的持续热情提出了质疑。 这些预测器利用 Transformer 对时间序列的时间标记 *temporal tokens* 的全局依赖关系进行建模，每个标记由同一时间戳的多个变量形成。 然而，由于性能下降和计算爆炸，Transformers 在预测具有较大**回溯窗口**的序列时面临挑战。 此外，每个时间标记的统一嵌入*embedding*融合了具有潜在未对齐时间戳和不同物理测量的多个变量，这可能无法学习以变量为中心的表示并导致无意义的注意力图。 在这项工作中，我们反思了 Transformer 组件的职责，并在不对基本组件进行任何修改的情况下重新调整了 Transformer 架构的用途。 我们提出 **iTransformer**，它简单地将注意力和前馈网络应用于反转维度。 具体来说，各个系列的时间点被嵌入到变量标记中，注意力机制利用变量标记来捕获多元相关性； 同时，前馈网络应用于每个变量标记来学习非线性表示。 iTransformer 模型在具有挑战性的现实世界数据集上达到了最先进的水平，这进一步增强了 Transformer 系列的性能、跨不同变量的泛化能力，以及更好地利用任意回溯窗口，使其成为一个很好的替代方案 时间序列预测的基本支柱。

### TimeMixer: Decomposable Multiscale Mixing for Time Series Forecasting
 - [paper](https://openreview.net/attachment?id=7oLshfEIC2&name=pdf)
 - 时间序列预测广泛应用于交通规划和天气预报等广泛应用中。 然而，现实世界的时间序列通常呈现复杂的时间变化，使得预测极具挑战性。 超越简单分解和多周期分析的主流范式，我们以多尺度混合的新颖观点分析时间变化，该观点基于直观但重要的观察，即时间序列在不同采样尺度下呈现不同的模式。 微观和宏观信息分别反映在精细和粗尺度上，从而可以从本质上理清复杂的变化。 基于这一观察，我们提出 **TimeMixer** 作为完全基于 MLP 的架构，具有过去可分解混合 (PDM) 和未来多重预测混合 (FMM) 模块，以在过去的提取和未来的预测阶段充分利用解开的多尺度序列。 具体来说，PDM将分解应用于多尺度序列，进一步将分解后的季节成分和趋势成分分别在由细到粗和由粗到细的方向上混合，依次聚合微观季节和宏观趋势信息。 FMM 进一步集成了多个预测变量，以在多尺度观测中利用互补的预测功能。 因此，TimeMixer 能够在长期和短期预测任务中实现一致的最先进性能，并具有良好的运行时效率。
    
## Time Series Representation Learning
### Explaining Time Series via Contrastive and Locally Sparse Perturbations
 - [paper](https://openreview.net/attachment?id=qDdSRaOiyb&name=pdf)
 - [code](https://anonymous.4open.science/r/ContraLSP-1146/)
 - 解释多元时间序列是一项复合挑战，因为它需要识别时间序列中的重要位置并匹配复杂的时间模式。 尽管以前的基于显着性的方法解决了这些挑战，但它们的扰动可能无法缓解分布偏移问题，这在异质样本中是不可避免的。 我们提出了 ContraLSP，一种局部稀疏模型，它引入反事实样本来构建无信息的扰动，但使用对比学习来保持分布。 此外，我们结合了特定于样本的稀疏门来生成更多二元倾斜和平滑的掩模，这可以轻松地整合时间趋势并简约地选择显着特征。 对合成数据集和真实数据集的实证研究表明，ContraLSP 的性能优于最先进的模型，证明时间序列数据的解释质量有了显着提高。
   
### T-Rep: Representation Learning for Time Series using Time-Embeddings
 - [paper](https://openreview.net/attachment?id=3y2TfP966N&name=pdf)
 - 多元时间序列对标准机器学习技术提出了挑战，因为它们通常是无标签的、高维的、有噪声的并且包含丢失的数据。 为了解决这个问题，我们提出了 **T-Rep**，一种以时间步粒度学习时间序列表示的自监督方法。 T-Rep 与其特征提取器一起学习时间的向量嵌入，以从信号中提取时间特征，例如趋势、周期性或分布偏移。 这些时间嵌入在借口任务中得到利用，以将平滑且细粒度的时间依赖性纳入表示中，并增强对丢失数据的鲁棒性。 我们在下游分类、预测和异常检测任务上评估 T-Rep。 与现有的时间序列自监督算法相比，它在所有三个任务中都表现出色。 我们在缺失数据的情况下测试了 T-Rep，事实证明它比同类产品更具弹性。 最后，我们提供了潜在空间可视化实验，强调了所学习的表示的可解释性。
   
### Soft Contrastive Learning for Time Series
- [paper](https://openreview.net/attachment?id=pAsQSWlDUf&name=pdf)
- 对比学习已被证明可以有效地以自我监督的方式学习时间序列的表示。 然而，对比时间序列中相邻时间戳的相似时间序列实例或值会导致忽略它们固有的相关性，从而导致学习表示的质量恶化。 为了解决这个问题，我们提出了 **SoftCLT**，一种简单而有效的时间序列软对比学习策略。 这是通过引入实例和时间对比损失以及范围从 0 到 1 的软分配来实现的。 具体来说，我们定义了软分配：1）按数据空间上时间序列之间的距离计算的实例对比损失，以及2）按时间戳差异计算的时间对比损失。 SoftCLT 是一种用于时间序列对比学习的即插即用方法，可以提高学习表示的质量，而无需附加任何附加功能。 在实验中，我们证明 SoftCLT 持续提高了各种下游任务的性能，包括分类、半监督学习、迁移学习和异常检测，显示出最先进的性能。

## Time Series Representation Generative Learning
### MG-TSD: Multi-Granularity Time Series Diffusion Models with Guided Learning Process
 - [paper](https://openreview.net/attachment?id=CZiY6OLktd&name=pdf)
 - 最近，扩散概率模型由于其生成高保真样本的卓越能力而在生成时间序列预测中引起了人们的关注。 然而，在概率时间序列预测任务中有效利用它们强大的建模能力仍然是一个悬而未决的问题，部分原因是它们的随机性带来的不稳定性的挑战。 为了应对这一挑战，我们引入了一种新颖的多粒度时间序列扩散 **（MG-TSD）** 模型，该模型通过利用数据中固有的粒度级别作为中间扩散步骤的给定目标来实现最先进的预测性能 指导扩散模型的学习过程。 构建目标的方法是通过观察扩散模型的前向过程（依次将数据分布破坏为标准正态分布）而激发的，该过程直观地与将细粒度数据平滑为粗粒度表示的过程一致， 这两者都会导致精细分布特征逐渐丧失。 在研究中，我们推导了一种新颖的多粒度引导扩散损失函数，并提出了一种简洁的实现方法，以有效利用各种粒度级别的粗粒度数据。 更重要的是，我们的方法不依赖额外的外部数据，使其具有通用性并适用于各个领域。 对现实世界数据集进行的大量实验表明，我们的 MG-TSD 模型优于现有的时间序列预测方法。
   
### Diffusion-TS: Interpretable Diffusion for General Time Series Generation
 - [paper](https://openreview.net/attachment?id=4h1apFjO99&name=pdf)
 - 去噪扩散概率模型（DDPM）正在成为生成模型的领先范例。 它最近在音频合成、时间序列插补和预测方面取得了突破。 在本文中，我们提出了 **Diffusion-TS**，一种基于扩散的新型框架，它通过使用具有解纠缠时间表示的编码器-解码器 Transformer 生成高质量的多元时间序列样本，其中分解技术指导 Diffusion-TS 捕获语义 时间序列的含义，而 Transformer 从噪声模型输入中挖掘详细的序列信息。 与现有方法不同，我们训练模型直接重建样本，而不是每个扩散步骤中的噪声，并结合基于傅立叶的损失项。 此外，结果表明，所提出的 Diffusion-TS 可以轻松扩展到条件生成任务，例如预测和插补，而无需任何模型更改。 这也激励我们进一步探索DiffusionTS在不规则设置下的表现。 最后，通过定性和定量实验，结果表明 Diffusion-TS 在时间序列的各种现实分析上取得了最先进的结果。
   
### Time-LLM: Time Series Forecasting by Reprogramming Large Language Models
 - [paper](https://openreview.net/attachment?id=Unb5CVPtae&name=pdf)
 - 时间序列预测在许多现实世界的动态系统中具有重要意义，并且已被广泛研究。 与自然语言处理 (NLP) 和计算机视觉 (CV) 中单个大型模型可以处理多个任务不同，时间序列预测模型通常是专门化的，需要针对不同的任务和应用程序进行不同的设计。 虽然预训练的基础模型在 NLP 和 CV 领域取得了令人印象深刻的进步，但它们在时间序列领域的发展却受到数据稀疏性的限制。 最近的研究表明，大型语言模型（LLM）对复杂的标记序列具有强大的模式识别和推理能力。 然而，如何有效地对齐时间序列数据和自然语言的模态以利用这些功能仍然是一个挑战。 在这项工作中，我们提出了 **TIME-LLM**，这是一个重新编程框架，可将 LLM 重新用于一般时间序列预测，同时保持主干语言模型不变。 我们首先使用文本原型对输入时间序列进行重新编程，然后将其输入到冻结的法学硕士中以对齐两种模式。 为了增强法学硕士利用时间序列数据进行推理的能力，我们提出了提示作为前缀（PaP），它丰富了输入上下文并指导重新编程的输入补丁的转换。 最后对 LLM 转换后的时间序列补丁进行投影以获得预测。 我们的综合评估表明，TIME-LLM 是一个强大的时间序列学习器，其性能优于最先进的专业预测模型。 此外，TIME-LLM 在少样本和零样本学习场景中都表现出色。
   
### Generative Modeling of Regular and Irregular Time Series Data via Koopman VAEs
 - [paper](https://openreview.net/attachment?id=eY7sLb0dVF&name=pdf)
 - [code](https://anonymous.4open.science/r/Time-LLM)
 - 生成真实的时间序列数据对于许多工程和科学应用都很重要。 现有的工作使用生成对抗网络（GAN）来解决这个问题。 然而，GAN 在训练过程中通常不稳定，并且可能会出现模式崩溃。 虽然众所周知，变分自动编码器（VAE）对于这些问题更加稳健，但（令人惊讶的是）它们很少被考虑用于时间序列生成。 在这项工作中，我们引入了 **Koopman VAE (KVAE)**，这是一种新的生成框架，它基于模型先验的新颖设计，并且可以针对规则和不规则训练数据进行优化。 受库普曼理论的启发，我们使用线性映射来表示潜在的条件先验动力学。 我们的方法通过两个所需的功能增强了生成建模：（i）可以通过利用对线性映射的特征值规定约束的光谱工具来实现合并领域知识； (ii) 可以使用动力系统理论的工具来研究系统的定性行为和稳定性。 我们的结果表明，在几个具有挑战性的合成和现实时间序列生成基准中，KVAE 的性能优于最先进的 GAN 和 VAE 方法。 无论是使用常规数据还是不规则数据进行训练，KVAE 都会生成可提高判别性和预测性指标的时间序列。 我们还提供了视觉证据，表明 KVAE 学习的概率密度函数可以更好地逼近经验地面真实分布
   
### Generative Learning for Financial Time Series with Irregular and Scale-Invariant Patterns
 - [paper](https://openreview.net/attachment?id=CdjnzWsQax&name=pdf)
 - 有限的数据可用性构成了训练金融应用深度学习模型的主要障碍。 由于与金融时间序列相关的不规则且尺度不变的模式（以不同的持续时间和幅度重复的时间动态），合成金融时间序列以增强现实世界的数据具有挑战性。 现有方法无法捕获这种动态，现有方法通常假设基础数据具有规律性和一致性。 我们开发了一种名为 **FTS-Diffusion** 的新颖生成框架，用于对由三个模块组成的不规则和尺度不变模式进行建模。 首先，我们开发了一种尺度不变的模式识别算法来提取持续时间和幅度变化的重复模式。 其次，我们构建一个基于扩散的生成网络来合成模式片段。 第三，我们对模式的时间转换进行建模，以聚合生成的片段。 大量实验表明，FTS-Diffusion 生成的合成金融时间序列与观察到的数据高度相似，优于最先进的替代方案。 两个下游实验表明，使用 FTS-Diffusion 生成的合成数据增强现实世界数据可将股市预测的误差降低高达 17.9%。 据我们所知，这是第一个生成具有不规则和尺度不变模式的复杂时间序列的工作，解决金融中的数据限制问题。

## Time Series Analysis
### GAFormer: Enhancing Timeseries Transformers Through Group-Aware Embeddings
 - [paper](https://openreview.net/attachment?id=c56TWtYp0W&name=pdf)
 - 分析多元时间序列在许多领域都很重要。 然而，由于复杂的通道间关系和动态变化，很难在多元数据集中学习鲁棒且可概括的表示。 在本文中，我们介绍了一种学习时空结构的新方法，并用它来改进变压器在时间序列数据集上的应用。 我们的框架学习一组组标记，并构建一个特定于实例的组嵌入（GE）层，该层将输入标记分配给少量组标记，以将结构纳入学习中。 然后，我们引入了一种新颖的架构，GroupAware transFormer (GAFormer)，它结合了空间和时间组嵌入，以在许多时间序列分类和回归任务上实现最先进的性能。 在对许多不同时间序列数据集的评估中，我们表明 GE 本身可以为许多主干提供很好的增强，并且通过耦合空间和时间组嵌入，GAFormer 可以超越现有的基线。 最后，我们展示了我们的方法如何在没有有关通道空间排序的信息的情况下识别数据中的潜在结构，并对复杂多元数据集底层的空间和时间结构进行更可解释的分解。

### SocioDojo: Building Lifelong Analytical Agents with Real-world Text and Time Series
 - [paper](https://openreview.net/attachment?id=s9z0HzWJJp&name=pdf)
 - 我们推出了 SocioDojo，这是一个开放式的终身学习环境，用于开发可立即部署的自主代理，能够对经济、金融、政治和文化等社会主题进行类似人类的分析和决策。 它由（1）来自新闻、社交媒体、报告等的信息源组成，（2）由书籍、期刊和百科全书构建的知识库，加上互联网和知识图谱搜索接口的工具箱，（3）30K高 -金融、经济、社会和民意调查中的高质量时间序列，支持一项名为“超级投资组合”的新颖任务，该任务可以可靠且可扩展地评估代理人的社会分析和决策能力，其灵感来自于以时间序列为资产的投资组合优化 “投资”。 我们还为超级投资组合任务提出了一种新颖的分析师助理-执行器架构，以及对输入新闻、文章等进行深入分析以协助决策的假设和证明提示。 我们进行实验和消融研究来探索影响性能的因素。 结果表明，与两个实验设置中最先进的方法相比，我们提出的方法实现了 32.4% 和 30.4% 的改进。
   
### Inherently Interpretable Time Series Classification via Multiple Instance Learning
 - [paper](https://openreview.net/attachment?id=xriGRsoAza&name=pdf)
 - 传统的时间序列分类 (TSC) 方法通常是黑匣子，模糊了对其决策过程的固有解释。 在这项工作中，我们利用多实例学习（MIL）来克服这个问题，并提出了一个名为 **MILLET** 的新框架：用于局部可解释时间序列分类的多实例学习。 我们将 MILLET 应用于现有的深度学习 TSC 模型，并展示它们如何在不影响（在某些情况下甚至提高）预测性能的情况下变得本质上可解释。 我们在 85 个 UCR TSC 数据集上评估了 MILLET，并提出了一个专门为促进可解释性评估而设计的新颖的合成数据集。 在这些数据集上，我们表明 MILLET 可以快速生成稀疏解释，其质量比其他众所周知的可解释性方法更高。 据我们所知，我们与 MILLET 的合作是第一个为 TSC 开发通用 MIL 方法并将其应用于广泛的领域的工作

### FITS: Modeling Time Series with 10k Parameters
 - [paper](https://openreview.net/attachment?id=bWcnvZ3qMb&name=pdf)
 - [code](https://anonymous.4open.science/r/FITS/README.md)
 - 在本文中，我们介绍了 **FITS**，一种轻量级但功能强大的时间序列分析模型。 与直接处理原始时域数据的现有模型不同，FITS 的运行原理是可以通过复杂频域中的插值来操纵时间序列，从而实现与时间序列预测和异常检测的最先进模型相媲美的性能 任务。 值得注意的是，FITS 通过大约 10k 参数的精简配置来实现这一目标，使其非常适合边缘设备，并为广泛的应用铺平了道路。

### ModernTCN: A Modern Pure Convolution Structure for General Time Series Analysis
 - [paper](https://openreview.net/attachment?id=vpJMJerXHU&name=pdf)
 - 近年来，基于 Transformer 和 MLP 的模型迅速崛起，并在时间序列分析中占据主导地位。 相比之下，卷积现在由于性能较差而在时间序列任务中失去动力。 本文研究了如何在时间序列分析中更好地使用卷积这一悬而未决的问题，并努力将卷积带回时间序列分析的舞台。 为此，我们对传统的TCN进行现代化改造，并进行时间序列相关的修改，使其更适合时间序列任务。 作为结果，我们提出了 ModernTCN，并通过时间序列社区中很少探索的方式成功解决了这个悬而未决的问题。 作为纯卷积结构，ModernTCN 在五个主流时间序列分析任务（长期和短期预测、插补、分类和异常检测）上仍然实现了一致的 state-of-the-art 性能，同时保持了基于卷积的效率优势 模型，因此比最先进的基于 Transformer 和 MLP 的模型提供了更好的效率和性能平衡。 我们的研究进一步表明，与之前基于卷积的模型相比，我们的 ModernTCN 具有更大的有效感受野（ERF），因此可以更好地释放卷积在时间序列分析中的潜力。

## Irregular Time Series 
### Stable Neural Stochastic Differential Equations in Analyzing Irregular Time Series Data
 - [paper](https://openreview.net/attachment?id=4VIgNuQ1pY&name=pdf)
 - 现实世界时间序列数据中不规则的采样间隔和缺失值对假设间隔一致和完整数据的传统方法提出了挑战。 神经常微分方程（神经 ODE）提供了一种替代方法，利用神经网络与 ODE 求解器相结合，通过参数化向量场学习连续潜在表示。 神经
随机微分方程（神经 SDE）通过合并扩散项来扩展神经 ODE，尽管这种添加并非微不足道，特别是在处理不规则间隔和缺失值时。 因此，仔细设计漂移和扩散函数对于保持稳定性和增强性能至关重要，而不谨慎的选择可能会导致不利的特性，例如缺乏强解、随机不稳定或不稳定的欧拉离散化，从而显着影响神经 SDE 的性能。 在本研究中，我们提出了三类稳定的神经 SDE：Langevin 型 SDE、线性噪声 SDE 和几何 SDE。 然后，我们严格证明了它们在分布变化下保持优异性能的鲁棒性，同时有效防止过度拟合。 为了评估我们方法的有效性，我们对用于插值、预测和分类任务的四个基准数据集进行了广泛的实验，并使用 30 个公共数据集在不同缺失率下分析了我们方法的稳健性。 我们的结果证明了所提出的方法在处理现实世界不规则时间序列数据方面的有效性。
